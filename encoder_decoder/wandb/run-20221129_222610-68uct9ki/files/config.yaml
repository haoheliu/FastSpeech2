wandb_version: 1

N_diff_steps:
  desc: null
  value: 100
_wandb:
  desc: null
  value:
    cli_version: 0.13.5
    framework: lightning
    is_jupyter_run: false
    is_kaggle_kernel: false
    python_version: 3.8.15
    start_time: 1669760770.255846
    t:
      1:
      - 1
      - 5
      - 9
      - 41
      - 53
      - 55
      2:
      - 1
      - 5
      - 9
      - 41
      - 53
      - 55
      3:
      - 13
      - 15
      - 16
      - 23
      4: 3.8.15
      5: 0.13.5
      8:
      - 5
augmentation:
  desc: null
  value:
    balanced_sampling: true
    mixup: 0.0
class_num:
  desc: null
  value: 527
cutoff:
  desc: null
  value: 1000
data:
  desc: null
  value:
    params:
      batch_size: 4
      train:
        params:
          crop_size: 256
          size: 384
        target: ldm.data.openimages.FullOpenImagesTrain
      validation:
        params:
          crop_size: 256
          size: 384
        target: ldm.data.openimages.FullOpenImagesValidation
      wrap: true
    target: main.DataModuleFromConfig
dataset:
  desc: null
  value: audioset
label_proj_dropout:
  desc: null
  value: 0.2
max_seq_len:
  desc: null
  value: 1000
model:
  desc: null
  value:
    base_learning_rate: 0.0001
    params:
      ddconfig:
        attn_resolutions: []
        ch: 128
        ch_mult:
        - 1
        - 2
        - 4
        - 4
        double_z: true
        dropout: 0.0
        in_channels: 1
        num_res_blocks: 2
        out_ch: 1
        resolution: 256
        z_channels: 4
      embed_dim: 4
      lossconfig:
        params:
          disc_in_channels: 1
          disc_start: 50001
          disc_weight: 0.5
          kl_weight: 1.0e-06
        target: ldm.modules.losses.LPIPSWithDiscriminator
      monitor: val/rec_loss
    target: ldm.models.autoencoder.AutoencoderKL
model_name:
  desc: null
  value: ClipLabel2Audio
multi_speaker:
  desc: null
  value: true
optimizer:
  desc: null
  value:
    anneal_rate: 0.5
    anneal_steps:
    - 30000000
    batch_size: 2
    betas:
    - 0.9
    - 0.98
    eps: 1.0e-09
    grad_acc_step: 1
    grad_clip_thresh: 1.0
    lr: 0.0001
    warm_up_step: 4000
    weight_decay: 0.0
path:
  desc: null
  value:
    ckpt_path: /mnt/fast/nobackup/scratch4weeks/hl01486/exps/audio_generation/audioset_16k/v2_cliplevel/ckpt/2_clipnormpre_ch64_mel64_s100
    log_path: /mnt/fast/nobackup/scratch4weeks/hl01486/exps/audio_generation/audioset_16k/v2_cliplevel/log/2_clipnormpre_ch64_mel64_s100
    result_path: /mnt/fast/nobackup/scratch4weeks/hl01486/exps/audio_generation/audioset_16k/v2_cliplevel/result/2_clipnormpre_ch64_mel64_s100
preprocessing:
  desc: null
  value:
    audio:
      max_wav_value: 32768.0
      sampling_rate: 16000
    energy:
      feature: frame_level
      normalization: true
    label:
      norm: true
      quantization: false
      threshold: 0.01
      top_k: 527
    mel:
      blur: false
      freqm: 0
      mean: -4.63
      mel_fmax: 8000
      mel_fmin: 0
      n_mel_channels: 64
      std: 2.74
      target_length: 1056
      timem: 0
    pitch:
      feature: frame_level
      normalization: true
    stft:
      filter_length: 1024
      hop_length: 160
      win_length: 1024
    text:
      language: en
      text_cleaners:
      - english_cleaners
    val_size: 32
step:
  desc: null
  value:
    log_step: 500
    save_step: 20000
    synth_step: 10000
    total_step: 3000000
    val_step: 10000
transformer:
  desc: null
  value:
    conv_filter_size: 1024
    conv_kernel_size:
    - 9
    - 1
    decoder_dropout: 0.2
    decoder_head: 5
    decoder_hidden: 64
    decoder_layer: 4
    encoder_dropout: 0.2
    encoder_head: 5
    encoder_hidden: 64
    encoder_layer: 4
unet_channel:
  desc: null
  value: 64
variance_embedding:
  desc: null
  value:
    energy_quantization: linear
    n_bins: 256
    pitch_quantization: linear
variance_predictor:
  desc: null
  value:
    dropout: 0.5
    filter_size: 256
    kernel_size: 3
vocoder:
  desc: null
  value:
    model: HiFi-GAN
    speaker: LJSpeech
